import os
import requests
from datetime import datetime
import time

def fetch_reddit_pain_points(subreddit):
    """
    æŠ“å–æŒ‡å®š Subreddit çš„æ½œåœ¨ç—›ç‚¹è´´
    """
    # å…³é”®è¯ç»„åˆï¼šå¯»æ‰¾â€œå›°éš¾â€ã€â€œæ‰‹åŠ¨â€ã€â€œå¯»æ‰¾Appâ€ã€â€œç°æœ‰å·¥å…·ç¼ºé¡¹â€
    keywords = "(manual OR 'hard to' OR 'is there an app' OR 'alternative to' OR 'problem' OR 'frusting')"
    url = f"https://www.reddit.com/r/{subreddit}/search.json?q={keywords}&restrict_sr=1&sort=new&t=week"

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            return f"### [!] æ— æ³•è®¿é—® r/{subreddit} (HTTP {response.status_code})\n\n"

        data = response.json()
        posts = data.get('data', {}).get('children', [])

        if not posts:
            return f"### r/{subreddit} æœ¬å‘¨æš‚æ— åŒ¹é…ç—›ç‚¹å†…å®¹\n\n"

        report = f"### ğŸ“ r/{subreddit} åŠ¨æ€\n\n"
        for post in posts[:8]: # é€‰å–å‰8æ¡é«˜ç›¸å…³å†…å®¹
            p = post['data']
            # æ—¶é—´è½¬æ¢
            post_time = datetime.fromtimestamp(p['created_utc']).strftime('%Y-%m-%d')

            report += f"#### [{p['title']}](https://reddit.com{p['permalink']})\n"
            report += f"- **å‘å¸ƒæ—¶é—´**: {post_time}\n"
            report += f"- **çƒ­åº¦**: ğŸ‘ {p['score']} | ğŸ’¬ {p['num_comments']} è¯„è®º\n"

            # æˆªå–æ‘˜è¦
            content = p.get('selftext', '')
            if content:
                summary = content[:300].replace('\n', ' ') + "..."
                report += f"- **æ‘˜è¦**: {summary}\n"
            report += "\n---\n"
        return report
    except Exception as e:
        return f"### [!] æŠ“å– r/{subreddit} å‘ç”Ÿè‡´å‘½é”™è¯¯: {str(e)}\n\n"

def main():
    start_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"å¼€å§‹æ‰§è¡Œå…¨çƒæ¢æµ‹ä»»åŠ¡: {start_time}")

    # ç›®æ ‡é¢†åŸŸ
    targets = {
        "CivilEngineering": "åœŸæœ¨å·¥ç¨‹",
        "Construction": "å»ºç­‘æ–½å·¥",
        "QuantitySurveying": "å·¥ç¨‹é€ ä»·/ä¼°ç®—",
        "RealEstate": "æˆ¿åœ°äº§å¼€å‘",
        "PropTech": "åœ°äº§ç§‘æŠ€"
    }

    report_content = f"# ğŸš€ å…¨çƒå»ºç­‘/åœŸæœ¨è¡Œæƒ…ä¸ç—›ç‚¹æ¢æµ‹æŠ¥å‘Š\n\n"
    report_content += f"> **ç”Ÿæˆæ—¶é—´**: {start_time} (UTC)\n"
    report_content += f"> **æ¢æµ‹è¯´æ˜**: æœ¬æŠ¥å‘Šè‡ªåŠ¨æ‰«æå…¨çƒç¤¾äº¤åª’ä½“ï¼Œæå–å…³äºâ€œæµç¨‹ç¹çâ€ã€â€œæ‰‹åŠ¨æ“ä½œâ€åŠâ€œå¯»æ‰¾æ•°å­—åŒ–æ–¹æ¡ˆâ€çš„çœŸå®è®¨è®ºã€‚\n\n"

    for sub, name in targets.items():
        print(f"æ­£åœ¨æ‰«æ: {sub} ({name})...")
        report_content += f"## ğŸ¢ é¢†åŸŸï¼š{name} (r/{sub})\n"
        report_content += fetch_reddit_pain_points(sub)
        time.sleep(2) # ç¤¼è²ŒæŠ“å–é™åˆ¶

    # ä¿å­˜æŠ¥å‘Š
    report_file = "PAIN_POINTS_REPORT.md"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(report_content)

    print(f"ä»»åŠ¡å®Œæˆï¼ŒæŠ¥å‘Šå·²ç”Ÿæˆè‡³ {report_file}")

if __name__ == "__main__":
    main()
